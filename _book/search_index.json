[
["index.html", "Translating between R and Python", " Translating between R and Python "],
["dataframes.html", "Dataframes Setup", " Dataframes In what follows we assume Python has access to a dataframe called mtcars which is constructed on the same basis as the R one. import pandas as pd mtcars = pd.read_csv(&quot;https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv&quot;, index_col=0) Selecting rows Selecting row by numeric index R mtcars[1,] #Select row number 1 mtcars[c(1,2),] #Select row numbers 1 and 2 This returns a 'data.frame': 1 obs. of 11 variables or a 'data.frame': 2 obs. of 11 variables Python mtcars.iloc[0,:] #Select row number 1 (zero based indexing) mtcars.iloc[[0,1],:] #Select rows number 1 and 2. This returns a pandas.core.series.Series if you select a single row, or a pandas.core.frame.DataFrame if you select multiple rows. Selecting row by named index R mtcars[&#39;Mazda RX4&#39;, ] mtcars[c(&#39;Mazda RX4&#39;,&#39;Mazda RX4 Wag&#39;), ] This returns a 'data.frame': 1 obs. of 11 variables or a 'data.frame': 2 obs. of 11 variables Python mtcars.loc[&#39;Mazda RX4&#39;,:] mtcars.loc[[&#39;Mazda RX4&#39;, &#39;Mazda RX4 Wag&#39;],:] This returns a pandas.core.series.Series if you select a single row, or a pandas.core.frame.DataFrame if you select multiple rows. Selecting columns Selecting column by numeric index R mtcars[,1 ] mtcars[,c(1,2)] If we select a single column, this return an atomic vector. If we select multiple columns, it returns a 'data.frame': 32 obs. of 2 variables: Python mtcars.iloc[:,0] If we select a single column, this returns a pandas.core.series.Series. If we select multiple columns, it returns a pandas.core.frame.DataFrame. Selecting individual ‘cells’ (items) Selecting item by numeric index R mtcars[1,1 ] This returns a numeric vector with a single item Python mtcars.iloc[0,0] This returns a float Selecting item by named index R mtcars[&#39;Mazda RX4&#39;,&#39;mpg&#39;] This returns a numeric atomic vector with a single item. Python mtcars.loc[&#39;Mazda RX4&#39;,&#39;mpg] This returns a float. Selecting items with a logical vector It is possible to use a logical vector (a series of ‘truthy’ and ‘falsey’ values) to filter a dataframe. For instance, if your rows are 1,2,3 a logical vector true, false, true will select rows 1 and 3. R # The following df has 3 rows and 3 columns df &lt;- read.csv(&quot;https://gist.githubusercontent.com/RobinL/dae60170438c5e0adcd0c68fbaa6abdf/raw/62747b776c63c9bd367bcdc11fe7d6a3459eaa12/tiny.csv&quot;, row.names = 1) logical_vector &lt;- c(TRUE,FALSE, TRUE) df[logical_vector,] df[,logical_vector] logical_vector &lt;- c(TRUE, FALSE) df[logical_vector,] #This works due to R&#39;s vector recyclig df[,logical_vector] For more on vector recycling in R, see here. Python df = pd.read_csv(&quot;https://gist.githubusercontent.com/RobinL/dae60170438c5e0adcd0c68fbaa6abdf/raw/62747b776c63c9bd367bcdc11fe7d6a3459eaa12/tiny.csv&quot;, index_col=0) logical_vector = [True, False, True] df.loc[logical_vector,:] df.loc[:,logical_vector] logical_vector = [True, False] df.loc[logical_vector,:] #Different behaviour to R - no recycling df.loc[:,logical_vector] Obtaining the index itself R names(mtcars) rownames(mtcars) These are both atomic vectors of strings. Python mtcars.index mtcars.columns These are both of type pandas.indexes.base.Index Edge cases Things can get ambiguous in two situations: You have integer row or column names which aren’t just ascending integers starting at 0 (Python) or 1 (R). This creates an ambiguity between indexing my name or by number You have an index with duplicate values. Integer row/columns names which aren’t just 1,2,3…,n In R, row names are always strings, which resolves this ambiguity Data for these examples are here R df &lt;- read.csv(&quot;https://gist.githubusercontent.com/RobinL/7378abcb98d70f642a4047f4e01fd428/raw/5e26ef7581804308cd244a499737ead03eba66e8/f.csv&quot;, row.names = 1) df[c(1,2,3),] # Selects rows in positions 1,2,3 df[c(1,2,3,7),] # Selects rows in positions 1,2,3 and a blank row df[c(&quot;2&quot;,&quot;4&quot;,&quot;6&quot;),] # #Selects rows named &quot;2&quot;,&quot;4&quot;, and &quot;6&quot;&quot; corresponding to position 1, 2 and 3 df[c(&quot;2&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;),] # Row &quot;5&quot; does not exist, so it creates a blank row in the results Python df = pd.read_csv(&quot;https://gist.githubusercontent.com/RobinL/7378abcb98d70f642a4047f4e01fd428/raw/5e26ef7581804308cd244a499737ead03eba66e8/f.csv&quot;, index_col=0) df.iloc[[0,1,2],:] #Selects rows in position 1, 2 and 3 df.iloc[[0,1,2,6],:] #IndexError: positional indexers are out-of-bounds df.loc[[2,4,6],:] #Selects rows named 2,4, and 6 corresponding to position 0, 1 and 2 df.loc[[2,4,6,99],:] #Selects rows named 2,4, and 6 corresponding to position 0, 1 and 2, plus creates a row of NA with index 99 You can also use the pandas function ix for this, but I advise against it. See advice on the use of ix here. Duplicated row or column names Consider this table. R df &lt;- read.csv(&quot;https://gist.githubusercontent.com/RobinL/05eea0870961a80814da5ae22f25f407/raw/bd6f6cd2cf8edd22763e2afa460bf9a7c9bdd79b/tiny_dup.csv&quot;, row.names=1) #Error in read.table(file = file, header = header, sep = sep, quote = quote, : # duplicate &#39;row.names&#39; are not allowed Python df = pd.read_csv(&quot;https://gist.githubusercontent.com/RobinL/05eea0870961a80814da5ae22f25f407/raw/bd6f6cd2cf8edd22763e2afa460bf9a7c9bdd79b/tiny_dup.csv&quot;, index_col=0, mangle_dupe_cols=False) df.loc[2, &quot;b&quot;] # Returns 2 rows and 2 columns Writing to a dataframe Writing to individual cells In what follows I use name based indexing, but the following would also work with numeric (positional) indexing. R #Edit existing value mtcars[&quot;Mazda RX4&quot;, &quot;mpg&quot;] = 21.1 #Create new value mtcars[&quot;Future car&quot;, &quot;mpg&quot;] = 999 #A new row is created. All values are set to NA except for &#39;mpg&#39; column mtcars[&quot;Future car&quot;, &quot;mpg&quot;] = &quot;Not known&quot; #Note that this has the effect of coercing all the other values in the &#39;mpg&#39; column into a string vector. Python #Edit existing value mtcars.loc[&quot;Mazda RX4&quot;, &quot;mpg&quot;] = 21.1 #Create new value mtcars.loc[&quot;Future Car&quot;, &quot;mpg&quot;] = 999 #Note that this has the effect of coercing all the other values in the &#39;mpg&#39; column into a string vector. mtcars.loc[&quot;Future Car&quot;, &quot;mpg&quot;] = &quot;Not known&quot; #This does not affect the other values in the &#39;mpg&#39; column 0.0.0.1 Writing a new row with multiple values R # If you have all the values for the new row you can do this mtcars[&quot;New car&quot;,] &lt;- &lt;- list(mpg = 100, cyl = 2, disp = NA, hp = NA, drat = NA, wt = NA, qsec = NA, vs = NA, am = NA, gear = NA, carb = NA) # This is probably a bad idea because it recycles the list for you mtcars[&quot;New car&quot;,] &lt;- data.frame(list(1,2,3)) #You can also edit an existing row like this: mtcars[&quot;Datsun 710&quot;,] &lt;- list(mpg = 100, cyl = 2, disp = NA, hp = NA, drat = NA, wt = NA, qsec = NA, vs = NA, am = NA, gear = NA, carb = NA) Python #Write mutilple values using a pandas series mtcars.loc[&quot;New car&quot;,:] = pd.Series({&quot;mpg&quot;: 100, &quot;cyl&quot;: 2}) #You don&#39;t need a full row. Where values don&#39;t exist in the series, NAs will be inserted into the new row mtcars.loc[&quot;Datsun 710&quot;,:] = pd.Series({&quot;mpg&quot;: 100, &quot;cyl&quot;: 2}) #Note that this overwrites all the unspecified coluns to NA Writing a new column with multiple values R df &lt;- read.csv(&quot;https://gist.githubusercontent.com/RobinL/dae60170438c5e0adcd0c68fbaa6abdf/raw/62747b776c63c9bd367bcdc11fe7d6a3459eaa12/tiny.csv&quot;, row.names = 1) #One option is df[,&quot;d&quot;] = c(1,2,3) #Another options is df[&quot;d&quot;] = c(1,2,3) Python df = pd.read_csv(&quot;https://gist.githubusercontent.com/RobinL/dae60170438c5e0adcd0c68fbaa6abdf/raw/c111232bb1fd564bae084be45c988d63053ab843/tiny.csv&quot;, index_col=0) #One option is: df.loc[:, &quot;d&quot;] = [1,2,3] #Another option is df[&quot;d&quot;] = [1,2,3] Subsetting and filtering Simple rows filter R filter_vector &lt;- mtcars[&quot;mpg&quot;] &gt; 20 mtcars[filter_vector, ] Python filter_vector = mtcars[&quot;mpg&quot;] &gt; 20 mtcars[filter_vector] #An alternative is mtcars.loc[filter_vector, :] Operations on columns Filter column names R mtcars[,!names(mtcars) %in% c(&quot;mpg&quot;, &quot;cyl&quot;)] Python mtcars[c for c in mtcars.columns if c not in [&quot;mpg&quot;, &quot;cyl&quot;]] #Or if you wanted to stick closer to the R syntax you could do: mtcars.loc[:,~np.in1d(mtcars.columns, [&quot;mpg&quot;, &quot;cyl&quot; ])] Sort order of columns R mtcars[,sort(names(mtcars))] Python mtcars[sorted(mtcars.columns)] Computing new columns from existing columns Simple addition R mtcars[&quot;kmpl&quot;] &lt;- mtcars[&quot;mpg&quot;]/2.35214583 Python mtcars[&quot;kmpl&quot;] = mtcars[&quot;mpg&quot;]/2.35214583 More complex operations Where possible you should vectorise your computations. R mtcars[&quot;ifoutput&quot;] &lt;- ifelse(mtcars[&quot;mpg&quot;] &gt; 15, &quot;yes&quot;, &quot;no&quot;) Python mtcars[&quot;ifoutput&quot;] = np.where(mtcars[&quot;mpg&quot;] &gt; 15, &quot;yes&quot;, &quot;no&quot;) Application of custom function across data frame Generally you should use vectorised operations to manupulate dataframe - this is much faster/more efficient. But if you need to here’s how to apply a function row by row: R fn_to_apply &lt;- function(row) { #row is a named character vector - there is implicit type conversion happening here if (row[&quot;mpg&quot;] &gt; 15) { if (row[&quot;carb&quot;] == 4) { return(&quot;one thing&quot;) } } return(&quot;another thing&quot;) } mtcars[&quot;new_variable&quot;] &lt;- apply(mtcars,MARGIN=1, fn_to_apply) Python def fn_to_apply(row): &quot;&quot;&quot; Note that row is a pandas.core.series.Series representing a single row of the df &quot;&quot;&quot; if row[&quot;mpg&quot;] &gt; 15: if row[&quot;carb&quot;] == 4: return &quot;one thing&quot; return &quot;another thing&quot; mtcars[&quot;new_variable&quot;] = mtcars.apply(fn_to_apply,axis=1) Here’s another way of doing this in r using the purr package: R fn_to_apply &lt;- function(row) { #row is a named character vector - there is implicit type conversion happening here if (row[&quot;mpg&quot;] &gt; 15) { if (row[&quot;carb&quot;] == 4) { return(&quot;one thing&quot;) } } return(&quot;another thing&quot;) } Other stuff 0.0.0.2 Piping Checkout this for 🐍. Suppose we want to filter then apply a function, then do a group by and a summary. We’ll use dplyr in R R fn_to_apply &lt;- function(row) { #row is a named character vector - there is implicit type conversion happening here if (row[&quot;mpg&quot;] &gt; 15) { if (row[&quot;carb&quot;] == 4) { return(&quot;one thing&quot;) } } return(&quot;another thing&quot;) } mtcars %&gt;% filter(mpg &gt; 10) %&gt;% by_row(fn_to_apply, .to = &quot;new_col&quot;, .collate = c(&quot;row&quot;)) %&gt;% group_by(new_col) %&gt;% summarise_each(funs(mean)) Python def pipe_fn(df): &quot;&quot;&quot; Pipe expects a function that takes a dataframe as argument and returns a dataframe. &quot;&quot;&quot; def fn_to_apply(row): if row[&quot;mpg&quot;] &gt; 15: if row[&quot;carb&quot;] == 4: return &quot;one thing&quot; return &quot;another thing&quot; df[&quot;new_col&quot;] = df.apply(fn_to_apply,axis=1) return df mtcars\\ .query(&quot;mpg &gt; 10&quot;)\\ .pipe(pipe_fn)\\ .groupby(&quot;new_col&quot;)\\ .mean() Transposition When you transpose an R dataframe, implicit type conversion can get you Pandas has an advantage here because columns can be of mixed type. R all(t(t(iris)) == iris) # returns false Python all(iris.T.T == iris) # returns true Pivot tables/cross tabulations This is quite tricky in R #Simple pivot table in the tidyverse library(dplyr) library(tidyr) mtcars %&gt;% group_by(cyl, vs) %&gt;% summarise(count_hp = n()) %&gt;% spread(vs, count_hp) #Pivot table with multiple values aggregatedwith different agg functions (see python version for clearer description) library(data.frame) df &lt;- merge(dcast(data.table(mtcars), cyl ~ vs, mean, value.var = &quot;mpg&quot;), dcast(data.table(mtcars), cyl ~ vs, length, value.var = &quot;hp&quot;), by = &quot;cyl&quot;) names(df) &lt;- c(&quot;cyl&quot;, &quot;mean_vs_0&quot;, &quot;mean_vs_1&quot;, &quot;count_vs_0&quot;, &quot;count_vs_1&quot;) Python #Simple Pivot table mtcars.pivot_table(index=&quot;cyl&quot;, columns=&quot;vs&quot;, values = &quot;hp&quot;, aggfunc=&quot;count&quot;) #Note the benfits of multi indexing in the following example df = mtcars.pivot_table(index=&quot;cyl&quot;, columns=&quot;vs&quot;, values = [&quot;mpg&quot;, &quot;hp&quot;], aggfunc={&quot;mpg&quot;:np.mean, &quot;hp&quot;:&quot;count&quot;}) df.columns = df.columns.set_levels([&#39;mpg_mean&#39;, &#39;hp_count&#39;], level=0) Setup Here are some notes on running the code in this .Rmd. To run the code, you’ll want to remove eval=FALSE from the code blocks. In what follows we are going to use the mtcars dataset. If you want to run this code in Python, you’ll need access to the dataset. You can get this by doing: pip install ggplot and then in python from ggplot import mtcars Note that in order for the Python code to execute, you need to make sure that Sys.which('python') returns the path for Anaconda rather than Mac OS default python. See here, here and here. The solution I found was cd ~ echo .Renviron &gt;&gt; PATH=/Users/robinlinacre/anaconda/bin "]
]
